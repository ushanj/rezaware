{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "149b7738",
   "metadata": {},
   "source": [
    "# Derive Top N Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "115dba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    WARNING CONTROL to display or ignore all warnings\n",
    "'''\n",
    "import warnings; warnings.simplefilter('ignore')     #switch betweeb 'default' and 'ignore'\n",
    "import traceback\n",
    "\n",
    "''' Set debug flag to view extended error messages; else set it to False to turn off debugging mode '''\n",
    "debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46d5864c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All functional APP-libraries in REZAWARE-package of REZAWARE-module imported successfully!\n",
      "All functional SPARKDBWLS-libraries in LOAD-package of ETL-module imported successfully!\n",
      "All functional SPARKCLEANNRICH-libraries in TRANSFORM-package of ETL-module imported successfully!\n",
      "All functional DATAPREP-libraries in ETP-package of ASSETS-module imported successfully!\n",
      "sparkNoSQLwls Class initialization complete\n",
      "dataPrep Class initialization complete\n",
      "\n",
      "Class initialization and load complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime, date, timedelta\n",
    "\n",
    "sys.path.insert(1,\"/home/nuwan/workspace/rezaware/\")\n",
    "import rezaware as reza\n",
    "from utils.modules.etl.load import sparkDBwls as sdb\n",
    "from utils.modules.etl.transform import sparkCleanNRich as scne\n",
    "from mining.modules.assets.etp import dataPrep as prep\n",
    "# from utils.modules.ml.timeseries import rollingstats as stats\n",
    "\n",
    "''' restart initiate classes '''\n",
    "if debug:\n",
    "    import importlib\n",
    "    reza = importlib.reload(reza)\n",
    "    sdb = importlib.reload(sdb)\n",
    "    scne = importlib.reload(scne)\n",
    "    prep = importlib.reload(prep)\n",
    "#     stats= importlib.reload(stats)\n",
    "    \n",
    "__desc__ = \"analyze crypto market capitalization time series data\"\n",
    "# clsSDB = sdb.SQLWorkLoads(desc=__desc__)\n",
    "clsSCNR=scne.Transformer(desc=__desc__)\n",
    "# clsStat=stats.RollingStats(desc=__desc__)\n",
    "clsPrep =prep.Warehouse(desc=__desc__)\n",
    "''' optional - if not specified class will use the default values '''\n",
    "# prop_kwargs = {\"WRITE_TO_TMP\":True,   # necessary to emulate the etl dag\n",
    "#               }\n",
    "print(\"\\nClass initialization and load complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0dd26e",
   "metadata": {},
   "source": [
    "## Read data from mcap_past\n",
    "We apply a query to select assets with mcap > 1.0 million. Any missing values are imputed with the mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76c04b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wait a moment, retrieving data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 124:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/08 16:59:52 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 127:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/08 17:00:03 WARN DAGScheduler: Broadcasting large task binary with size 6.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 138:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/08 17:01:57 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 148:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/08 17:02:56 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 158:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/08 17:03:57 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 161:============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 235553 rows and 15 columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "_from_date = '2022-01-05'\n",
    "_to_date = '2022-01-10'\n",
    "# _query = \"select * from warehouse.mcap_past \"+\\\n",
    "#         f\"where mcap_date >= '{_from_date}' and \"+\\\n",
    "#         f\"mcap_date <= '{_to_date}'\"\n",
    "_query = \"select * from warehouse.mcap_past wmp \"+\\\n",
    "        f\"where wmp.mcap_date between '{_from_date}' and '{_to_date}' \"+\\\n",
    "        f\"and wmp.mcap_value > 1000000 \"+\\\n",
    "        f\"and wmp.mcap_value = (select MAX(mcap_value ) \"+\\\n",
    "        f\"from warehouse.mcap_past where wmp.asset_name=asset_name)\"\n",
    "_kwargs = {\n",
    "    \"TABLENAME\":'warehouse.mcap_past',\n",
    "    \"COLUMN\":'mcap_date',\n",
    "    \"FROMDATETIME\":_from_date,\n",
    "    \"TODATETIME\":_to_date,\n",
    "    \"PARTITIONS\":2,\n",
    "    \"AGGREGATE\":'avg',\n",
    "    \"PIVCOLUMNS\":['dxd','sofi','wsn','xmx','uqc','btr','unic','nex','noia',\n",
    "                  'hanu','aca','bbs','xvs','pnd','shake','stpl','dtx','tethys',\n",
    "                  'kyoko','boba','nlife','rare','eved','yfl','fkx','flixx',\n",
    "                  'drk','meto','glide','shr','tetu','mft','cmerge','shmn','tronpad']\n",
    "}\n",
    "\n",
    "# print(clsSpark.dbSchema)\n",
    "mcap_sdf = clsPrep.read_n_clean_mcap(query=_query,**_kwargs)\n",
    "# mcap_sdf = clsROR.read_n_clean_mcap(**_kwargs)\n",
    "\n",
    "print(\"Loaded %d rows and %d columns\" % (mcap_sdf.count(),len(mcap_sdf.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c031155e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 212:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/08 18:24:09 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 215:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+----------------+--------------------+---------+-------------------+\n",
      "|                uuid| mcap_date|      asset_name|          mcap_value|mcap_rank|            mcap_dt|\n",
      "+--------------------+----------+----------------+--------------------+---------+-------------------+\n",
      "|6397ab7b7cc473c58...|2022-01-05|synthetify_token|14232382.38223430...|     null|2022-01-05 00:00:00|\n",
      "|639720647cc473c58...|2022-01-05|            celo|2214150436.063860...|     null|2022-01-05 00:00:00|\n",
      "|639720647cc473c58...|2022-01-05|            celo|2193746148.681650...|     null|2022-01-05 00:00:00|\n",
      "+--------------------+----------+----------------+--------------------+---------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "mcap_sdf.select(F.col('uuid'),\n",
    "                F.col('mcap_date'),\n",
    "                F.col('asset_name'),\n",
    "                F.col('mcap_value'),\n",
    "                F.col('mcap_rank'),\n",
    "                F.col('mcap_dt')).show(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b53a90a",
   "metadata": {},
   "source": [
    "## Compute LogROR for all assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358fa4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs={\n",
    "    \"PREVALCOLNAME\":'mcap_prev_val',\n",
    "    \"DIFFCOLNAME\":'mcap_diff',\n",
    "    \"LOGCOLNAME\":'log_ror'\n",
    "}\n",
    "_mcap_log_ror, _log_col = clsPrep.get_log_ror(\n",
    "    data=mcap_sdf,\n",
    "    num_col_name=\"mcap_value\",\n",
    "    part_column ='asset_name',\n",
    "    **kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91f506ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 256:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/08 18:35:37 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/08 18:35:44 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 262:============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/08 18:35:52 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 266:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/08 18:35:53 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n",
      "+--------------------+-----------+----------+--------------------+--------------------+\n",
      "|                uuid| asset_name| mcap_date|          mcap_value|             log_ror|\n",
      "+--------------------+-----------+----------+--------------------+--------------------+\n",
      "|                null|axial_token|2022-01-05|4702556.663127339...| -0.6692981455062752|\n",
      "|6396fb727cc473c58...|axial_token|2022-01-05|5188795.589442330...|-0.04273233278400148|\n",
      "|6396fb727cc473c58...|axial_token|2022-01-05|5740784.796051540...|-0.03844934887355...|\n",
      "+--------------------+-----------+----------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 271:>                                                        (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "_mcap_log_ror.select(F.col('uuid'),\n",
    "                     F.col('asset_name'),\n",
    "                     F.col('mcap_date'),\n",
    "                     F.col('mcap_value'), \n",
    "                     F.col('log_ror'))\\\n",
    "            .filter((F.col('log_ror').isNotNull()) & \n",
    "                    (F.col('asset_name')=='axial_token'))\\\n",
    "            .show(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d7e14d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 174:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/08 17:21:21 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 184:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/08 17:22:43 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 194:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/08 17:23:47 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/08 17:24:00 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 200:============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/08 17:24:14 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 204:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/08 17:24:19 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 209:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-----------+------------+----------+--------------------+---------+--------------------+----------+------------+-----------+-----------+-------------+-------------+-------------------+--------------------+--------------------+-------------------+\n",
      "|                uuid|data_source| asset_name|asset_symbol| mcap_date|          mcap_value|mcap_rank|          created_dt|created_by|created_proc|modified_dt|modified_by|modified_proc|deactivate_dt|            mcap_dt| mcap_value_prev_val|           mcap_diff|            log_ror|\n",
      "+--------------------+-----------+-----------+------------+----------+--------------------+---------+--------------------+----------+------------+-----------+-----------+-------------+-------------+-------------------+--------------------+--------------------+-------------------+\n",
      "|                null|       null|axial_token|        null|2022-01-05|4702556.663127339...|     null|                null|      null|        null|       null|       null|         null|         null|               null|1007015.028589230...|3695541.634538109...|-0.6692981455062752|\n",
      "|                null|       null|     ionomy|        null|2022-01-05|5224328.823575757...|     null|                null|      null|        null|       null|       null|         null|         null|               null|1482054.289554720...|3742274.534021037...| -0.547166688974698|\n",
      "|6397ad3f7cc473c58...|  coingecko|tether_eurt|        eurt|2022-01-05|188029195.2056480...|     null|2022-12-25 04:23:...|farmraider|     Unknown|       null|       null|         null|         null|2022-01-05 00:00:00|57261300.87730749...|130767894.3283405...|-0.5163642130867019|\n",
      "+--------------------+-----------+-----------+------------+----------+--------------------+---------+--------------------+----------+------------+-----------+-----------+-------------+-------------+-------------------+--------------------+--------------------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a2f6f24",
   "metadata": {},
   "source": [
    "## Weighted Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a39609d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 109:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 09:49:03 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 09:49:08 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 115:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 09:49:13 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 127:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 09:51:38 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 09:51:43 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 133:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 09:51:48 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 137:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 09:51:50 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 151:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 09:53:24 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 09:53:28 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 157:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 09:53:32 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 161:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 09:53:34 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 175:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 09:55:48 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 09:55:52 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 181:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 09:55:57 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 193:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 09:57:54 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 09:57:59 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 199:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 09:58:05 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 203:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 09:58:08 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 09:58:08 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 213:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 09:58:11 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 222:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:00:47 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:00:51 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 228:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:00:55 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n",
      "23/01/28 10:00:57 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 246:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:02:05 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:02:10 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 252:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:02:17 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 256:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:02:19 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 270:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:03:16 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:03:21 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 276:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:03:26 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 280:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:03:27 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 294:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:04:23 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:04:28 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 300:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:04:34 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 304:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:04:36 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 318:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:06:24 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:06:31 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 328:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:06:40 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n",
      "23/01/28 10:06:43 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 342:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:08:59 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:09:04 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 348:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:09:09 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 352:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:09:12 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:09:13 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 362:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:09:16 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 371:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:10:55 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:10:59 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 377:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:11:04 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 381:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:11:06 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:11:07 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 391:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:11:09 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 400:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:12:26 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:12:30 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 406:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:12:34 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n",
      "23/01/28 10:12:36 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 415:>                                                        (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:12:37 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n",
      "23/01/28 10:12:38 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 429:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:13:49 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:13:53 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 435:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:13:57 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n",
      "23/01/28 10:14:00 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:14:00 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 449:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:14:03 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 458:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:15:22 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:15:26 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 464:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:15:31 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 468:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:15:33 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 473:>                                                        (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:15:34 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 478:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 10:15:36 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 484:>                                                        (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'mcap_date': datetime.date(2022, 1, 6),\n",
       "  'asset_name': ['charg_coin', 'roge', 'neurotoken'],\n",
       "  'log_ror': [0.25040658289005097, 0.2300847277541936, 0.22315158781277547],\n",
       "  'weights': [0.5934458610550608, 0.11493828956433183, 0.2916158493806074],\n",
       "  'mcap_value': [Decimal('5220183.74772765300000000000'),\n",
       "   Decimal('2145261.20389485800000000000'),\n",
       "   Decimal('1332808.07022394360000000000')]},\n",
       " {'mcap_date': datetime.date(2022, 1, 7),\n",
       "  'asset_name': ['robotina', 'sentinel_group', 'gravity_finance'],\n",
       "  'log_ror': [0.9659091703444093, 0.415784053356342, 0.24974754544640954],\n",
       "  'weights': [0.6295957738354031, 0.05237806329355537, 0.3180261628710416],\n",
       "  'mcap_value': [Decimal('1018345.62651913000000000000'),\n",
       "   Decimal('5870017.17622237100000000000'),\n",
       "   Decimal('2031961.70641057660000000000')]},\n",
       " {'mcap_date': datetime.date(2022, 1, 8),\n",
       "  'asset_name': ['primecoin', 'neurochain', 'bitcoin_scrypt'],\n",
       "  'log_ror': [0.45615688364912843, 0.4011424725185939, 0.28212772816557075],\n",
       "  'weights': [0.543694041943098, 0.28722923986128157, 0.16907671819562034],\n",
       "  'mcap_value': [Decimal('1475785.78355717600000000000'),\n",
       "   Decimal('1414947.27726557060000000000'),\n",
       "   Decimal('1308454.50419590090000000000')]},\n",
       " {'mcap_date': datetime.date(2022, 1, 9),\n",
       "  'asset_name': ['leverj_gluon', 'onooks', 'falconx'],\n",
       "  'log_ror': [0.5012158266094365, 0.22671200830424368, 0.16952631379675884],\n",
       "  'weights': [0.5942044176776197, 0.19710672092724646, 0.2086888613951338],\n",
       "  'mcap_value': [Decimal('2260417.60434771400000000000'),\n",
       "   Decimal('6378494.16271787800000000000'),\n",
       "   Decimal('1081416.01318761400000000000')]},\n",
       " {'mcap_date': datetime.date(2022, 1, 10),\n",
       "  'asset_name': ['charg_coin', 'matryx', 'bitcoinpos'],\n",
       "  'log_ror': [0.6574680456259401, 0.2861116369010913, 0.20342319564693787],\n",
       "  'weights': [0.4453207926976063, 0.34821271988748376, 0.20646648741490986],\n",
       "  'mcap_value': [Decimal('1148729.34965566430000000000'),\n",
       "   Decimal('2246173.23459720500000000000'),\n",
       "   Decimal('14522857.41687161100000000000')]}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_cols={\n",
    "    \"NAMECOLUMN\":'asset_name',\n",
    "    \"DATECOLUMN\":'mcap_date',\n",
    "    \"RORCOLUMN\" :_log_col,\n",
    "    \"MCAPCOLUMN\":'mcap_value',\n",
    "    \"WEIGHTCOLUMN\":'weights',\n",
    "}\n",
    "_l_exp_wts,_cols_dict=clsMPT.get_weighted_mpt(\n",
    "    data=_mcap_log_ror,\n",
    "    cols_dict=_cols,\n",
    "#     date_col='mcap_date',\n",
    "#     val_col='log_ror',\n",
    "#     name_col='asset_name',\n",
    "    topN=3,\n",
    "    size=5,\n",
    "    **_kwargs,\n",
    ")\n",
    "# print(\"Dates: %s\" % str(_wr_dates))\n",
    "# print(\"Data : row=%d columns=%d\" % (_wr_data.count(),len(_wr_data.columns)))\n",
    "_l_exp_wts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97eaaeb",
   "metadata": {},
   "source": [
    "## Write MPT to MongoDB\n",
    "\n",
    "* Collection name = \"mpt.\"+date(YYYY-MM-DD)\n",
    "* document structure: \\_id, date, asset, mcap.value, mcap.weight, mcap.ror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccad5a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert 5 documents\n"
     ]
    }
   ],
   "source": [
    "_kwargs = {\n",
    "    \"DESTINDBNAME\":'tip-daily-mpt',\n",
    "    \"COLLPREFIX\" : 'mpt.for'\n",
    "}\n",
    "mpt_list_ = clsMPT.write_mpt_to_db(\n",
    "    mpt_data=_l_exp_wts,\n",
    "    cols_dict=_cols_dict,\n",
    "    **kwargs,\n",
    ")\n",
    "print(\"Upsert %d documents\" % len(mpt_list_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb99563",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
